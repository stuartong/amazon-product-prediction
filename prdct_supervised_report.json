{
    "preprocess_features": {
        "category_thresh": 500,
        "tfidf": true,
        "handpicked": true,
        "wordvec": true,
        "wordvec_model": "glove-wiki-gigaword-300",
        "pca": true,
        "pca_comp": 55
    },
    "model_specs": {
        "model_type": [
            "LogisticRegression"
        ],
        "params": {
            "scale": true,
            "oversample": false,
            "gscv": true,
            "n_jobs": -1,
            "return_train_score": false,
            "split": 0.8,
            "random_state": 42,
            "C": 100,
            "gamma": 1,
            "kernel": "rbf"
        }
    },
    "scores_report": {
        "training accuracy": 0.640031416642553,
        "Test accuracy": 0.6296296296296297,
        "Validation accuracy": 0.6421957671957672,
        "Dummy most frequent accuracy": 0.5634920634920635,
        "Dummy uniform accuracy": 0.5,
        "Test F1-score": 0.6182802469664268,
        "Validation F1-score": 0.6336786039084126,
        "Dummy most frequent F1-Score": 0.40617194424301023,
        "Dummy Unified F1-score": 0.5020142515935813,
        "Test Matthews Corrcoef": 0.23065880708374203,
        "Validation Matthews Corrcoef": 0.26676854331059124,
        "Dummy Unified Mathews Corrcoef": -0.0011854256769998402,
        "Classification Report - Test": {
            "0": {
                "precision": 0.641747572815534,
                "recall": 0.7758215962441315,
                "f1-score": 0.7024442082890542,
                "support": 1704
            },
            "1": {
                "precision": 0.6037344398340249,
                "recall": 0.4409090909090909,
                "f1-score": 0.509632224168126,
                "support": 1320
            },
            "accuracy": 0.6296296296296297,
            "macro avg": {
                "precision": 0.6227410063247794,
                "recall": 0.6083653435766112,
                "f1-score": 0.6060382162285901,
                "support": 3024
            },
            "weighted avg": {
                "precision": 0.6251545385775736,
                "recall": 0.6296296296296297,
                "f1-score": 0.6182802469664268,
                "support": 3024
            }
        },
        "Classification Report - Validation": {
            "0": {
                "precision": 0.6469408224674023,
                "recall": 0.7733812949640287,
                "f1-score": 0.7045330420535227,
                "support": 1668
            },
            "1": {
                "precision": 0.6330097087378641,
                "recall": 0.4808259587020649,
                "f1-score": 0.5465213746856664,
                "support": 1356
            },
            "accuracy": 0.6421957671957672,
            "macro avg": {
                "precision": 0.6399752656026332,
                "recall": 0.6271036268330468,
                "f1-score": 0.6255272083695946,
                "support": 3024
            },
            "weighted avg": {
                "precision": 0.6406939341680459,
                "recall": 0.6421957671957672,
                "f1-score": 0.6336786039084126,
                "support": 3024
            }
        }
    }
}